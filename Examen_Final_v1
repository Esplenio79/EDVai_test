##Ingestamos los archivos relacionados con transporte aéreo de Argentina con WGET desde:
2021:
https://dataengineerpublic.blob.core.windows.net/data-engineer/2021-informe-ministerio.csv
2022:
https://dataengineerpublic.blob.core.windows.net/data-engineer/202206-informe-ministerio.csv
Aeropuertos_detalles:
https://dataengineerpublic.blob.core.windows.net/data-engineer/aeropuertos_detalle.csv

##Los enviamos a hdfs y verificamos que se encuentran en la carpeta /ingest
plchiapero@LAPTOP-HJNIQGOK:~$ docker exec -it edvai_hadoop /bin/bash
root@7b946e8f971d:/# su hadoop
hadoop@7b946e8f971d:/$ hdfs dfs -ls /ingest/
Found 4 items
-rw-r--r--   1 hadoop supergroup   32322556 2024-09-29 17:21 /ingest/2021-informe-ministerio.csv
-rw-r--r--   1 hadoop supergroup   22833520 2024-09-29 18:09 /ingest/202206-informe-ministerio.csv
-rw-r--r--   1 hadoop supergroup     136007 2024-09-29 18:10 /ingest/aeropuertos_detalle.csv

hadoop@7b946e8f971d:/$ pyspark

##Cambiamos la separación de los datos de los archivos de ";" a ","
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.2.0
      /_/

Using Python version 3.8.10 (default, Mar 15 2022 12:22:08)
Spark context Web UI available at http://7b946e8f971d:4040
Spark context available as 'sc' (master = yarn, app id = application_1727916311286_0001).
SparkSession available as 'spark'.

>>> df2022 = spark.read.option("header", "true").option("sep", ";").csv("/ingest/202206-informe-ministerio.csv")
>>> df2021 = spark.read.option("header", "true").option("sep", ";").csv("/ingest/2021-informe-ministerio.csv")
>>> df2022.printSchema()
root
 |-- Fecha: string (nullable = true)
 |-- Hora UTC: string (nullable = true)
 |-- Clase de Vuelo (todos los vuelos): string (nullable = true)
 |-- Clasificación Vuelo: string (nullable = true)
 |-- Tipo de Movimiento: string (nullable = true)
 |-- Aeropuerto: string (nullable = true)
 |-- Origen / Destino: string (nullable = true)
 |-- Aerolinea Nombre: string (nullable = true)
 |-- Aeronave: string (nullable = true)
 |-- Pasajeros: string (nullable = true)
 |-- Calidad dato: string (nullable = true)

>>> df2021.printSchema()
root
 |-- Fecha: string (nullable = true)
 |-- Hora UTC: string (nullable = true)
 |-- Clase de Vuelo (todos los vuelos): string (nullable = true)
 |-- Clasificación Vuelo: string (nullable = true)
 |-- Tipo de Movimiento: string (nullable = true)
 |-- Aeropuerto: string (nullable = true)
 |-- Origen / Destino: string (nullable = true)
 |-- Aerolinea Nombre: string (nullable = true)
 |-- Aeronave: string (nullable = true)
 |-- Pasajeros: string (nullable = true)
 |-- Calidad dato: string (nullable = true)

##Unimos las dos tablas con UNION
>>> df_2122 = df2021.union(df2022)

##Creamos una vista de esa nueva tabla
>>> df_2122.createOrReplaceTempView("df_2122_v")

##Casteamos y verificamos los cambios con printSchema y show
>>> from pyspark.sql.functions import to_date, col
>>> df_2122_cast = df_2122.withColumn("fecha", to_date(col("fecha"), "dd/MM/yyyy")).withColumn("pasajeros", col("pasajeros").cast("int"))
>>> df_2122_cast.printSchema()
root
 |-- fecha: date (nullable = true)
 |-- Hora UTC: string (nullable = true)
 |-- Clase de Vuelo (todos los vuelos): string (nullable = true)
 |-- Clasificación Vuelo: string (nullable = true)
 |-- Tipo de Movimiento: string (nullable = true)
 |-- Aeropuerto: string (nullable = true)
 |-- Origen / Destino: string (nullable = true)
 |-- Aerolinea Nombre: string (nullable = true)
 |-- Aeronave: string (nullable = true)
 |-- pasajeros: integer (nullable = true)
 |-- Calidad dato: string (nullable = true)

>>> df_2122_cast.show(10)
+----------+--------+---------------------------------+-------------------+------------------+----------+----------------+--------------------+----------------+---------+------------+
|     fecha|Hora UTC|Clase de Vuelo (todos los vuelos)|Clasificación Vuelo|Tipo de Movimiento|Aeropuerto|Origen / Destino|    Aerolinea Nombre|        Aeronave|pasajeros|Calidad dato|
+----------+--------+---------------------------------+-------------------+------------------+----------+----------------+--------------------+----------------+---------+------------+
|2021-01-01|   00:02|             Vuelo Privado con...|          Domestico|          Despegue|       PAR|             ROS|                   0|    PA-PA-28-181|        0|  DEFINITIVO|
|2021-01-01|   00:24|                          Regular|          Domestico|        Aterrizaje|       EZE|             GRA|AEROLINEAS ARGENT...|     BO-B737-8MB|       70|  DEFINITIVO|
|2021-01-01|   00:26|                          Regular|          Domestico|        Aterrizaje|       EZE|             ECA|AEROLINEAS ARGENT...|      BO-737-800|       70|  DEFINITIVO|
|2021-01-01|   00:29|                          Regular|          Domestico|        Aterrizaje|       EZE|             SAL|AEROLINEAS ARGENT...|    BO-B-737-76N|       12|  DEFINITIVO|

##Generamos una vista de este nuevo df
>>> df_2122_cast.createOrReplaceTempView("df_2122_cast_v")

##Casteamos de acuerdo a lo solicitado en el punto del Schema 1
>>> df_cast_nombres = spark.sql("SELECT to_date(fecha, 'dd/MM/yyyy') AS date, CAST(`Hora UTC` AS STRING) AS hora_utc, CAST(`Clase de Vuelo (todos los vuelos)` AS STRING) AS clase_de_vuelo, CAST(`Clasificación Vuelo` AS STRING) AS clasificacion_de_vuelo, CAST(`Tipo de Movimiento` AS STRING) AS tipo_de_movimiento, CAST(aeropuerto AS STRING) AS aeropuerto, CAST(`Origen / Destino` AS STRING) AS origen_destino, CAST(`Aerolinea Nombre` AS STRING) AS aerolinea_nombre, CAST(aeronave AS STRING) AS aeronave, COALESCE(CAST(pasajeros AS INTEGER), 0) AS pasajeros FROM df_2122_cast_v")
>>> df_cast_nombres.printSchema()
root
 |-- date: date (nullable = true)
 |-- hora_utc: string (nullable = true)
 |-- clase_de_vuelo: string (nullable = true)
 |-- clasificacion_de_vuelo: string (nullable = true)
 |-- tipo_de_movimiento: string (nullable = true)
 |-- aeropuerto: string (nullable = true)
 |-- origen_destino: string (nullable = true)
 |-- aerolinea_nombre: string (nullable = true)
 |-- aeronave: string (nullable = true)
 |-- pasajeros: integer (nullable = false)

>>> df_cast_nombres.show(2)
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+------------+---------+
|      date|hora_utc|      clase_de_vuelo|clasificacion_de_vuelo|tipo_de_movimiento|aeropuerto|origen_destino|    aerolinea_nombre|    aeronave|pasajeros|
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+------------+---------+
|2021-01-01|   00:02|Vuelo Privado con...|             Domestico|          Despegue|       PAR|           ROS|                   0|PA-PA-28-181|        0|
|2021-01-01|   00:24|             Regular|             Domestico|        Aterrizaje|       EZE|           GRA|AEROLINEAS ARGENT...| BO-B737-8MB|       70|
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+------------+---------+
only showing top 2 rows

>>> df_cast_nombres.createOrReplaceTempView("df_2122_cast_v_final")
>>> spark.sql("DESCRIBE df_2122_cast_v_final").show()
+--------------------+---------+-------+
|            col_name|data_type|comment|
+--------------------+---------+-------+
|                date|     date|   null|
|            hora_utc|   string|   null|
|      clase_de_vuelo|   string|   null|
|clasificacion_de_...|   string|   null|
|  tipo_de_movimiento|   string|   null|
|          aeropuerto|   string|   null|
|      origen_destino|   string|   null|
|    aerolinea_nombre|   string|   null|
|            aeronave|   string|   null|
|           pasajeros|      int|   null|
+--------------------+---------+-------+

## En HIVE, damos de alta la BD que llamamos examen_final, luego chequeamos el alta correcta, y finalmente elegimos usar la BD que dimos de alta

hive> create database examen_final;
hive> show databases;
OK
examen_final
Time taken: 0.027 seconds, Fetched: 1 row(s)
hive> use examen_final;
OK

##Damos de alta la tabla 
hive> CREATE EXTERNAL TABLE IF NOT EXISTS examen_final.aeropuerto_tabla (fecha date, hora_utc string, clase_de_vuelo string, clasificacion_de_vuelo string, tipo_de_movimiento string, aeropuerto string, origen_destino string, aerolinea_nombre string, aeronave string, pasajeros int)
    > row format delimited
    > fields terminated by ','
    > location '/tables/external/examen_final';
OK
Time taken: 0.863 seconds
hive>

##Vuelvo a spark, y envío la vista del df a hive

>>> spark.sql("insert into examen_final.aeropuerto_tabla select * from df_2122_cast_v_final")
2024-11-24 19:59:11,787 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
DataFrame[]
>>>

#Chequeo que en hive esté la tabla
hive> select * from aeropuerto_tabla limit 10;
OK
2021-01-01      00:02   Vuelo Privado con Matrícula Nacional    Domestico       Despegue        PAR
ROS     0       PA-PA-28-181    0
2021-01-01      00:24   Regular Domestico       Aterrizaje      EZE     GRA     AEROLINEAS ARGENTINAS SABO-B737-8MB     70
2021-01-01      00:26   Regular Domestico       Aterrizaje      EZE     ECA     AEROLINEAS ARGENTINAS SABO-737-800      70
2021-01-01      00:29   Regular Domestico       Aterrizaje      EZE     SAL     AEROLINEAS ARGENTINAS SABO-B-737-76N    12
2021-01-01      00:37   Regular Domestico       Aterrizaje      EZE     TUC     AEROLINEAS ARGENTINAS SAEMB-ERJ190100IGW        26
2021-01-01      00:59   Regular Internacional   Aterrizaje      EZE     SBGR    TURK HAVA YOLLARI (TURKISH AIRLINES CO.)        0       62
2021-01-01      01:00   Vuelo Privado con Matrícula Nacional    Domestico       Aterrizaje      ROS
PAR     0       PA-PA-28-181    0
2021-01-01      01:12   Regular Internacional   Despegue        EZE     MMMX    AEROVIAS DE MEXICO - AEROMEXICO 0       198
2021-01-01      01:52   Regular Internacional   Despegue        EZE     KDFW    AMERICAN AIRLINES INC.
0       193
2021-01-01      02:08   Regular Internacional   Despegue        EZE     KMIA    AMERICAN AIRLINES INC.
0       255
Time taken: 1.364 seconds, Fetched: 10 row(s)
hive> describe aeropuerto_tabla;
OK
fecha                   date
hora_utc                string
clase_de_vuelo          string
clasificacion_de_vuelo  string
tipo_de_movimiento      string
aeropuerto              string
origen_destino          string
aerolinea_nombre        string
aeronave                string
pasajeros               int
Time taken: 0.071 seconds, Fetched: 10 row(s)
hive> describe formatted aeropuerto_tabla;
OK
# col_name              data_type               comment

fecha                   date
hora_utc                string
clase_de_vuelo          string
clasificacion_de_vuelo  string
tipo_de_movimiento      string
aeropuerto              string
origen_destino          string
aerolinea_nombre        string
aeronave                string
pasajeros               int

# Detailed Table Information
Database:               examen_final
Owner:                  hadoop
CreateTime:             Sun Nov 24 19:56:01 ART 2024
LastAccessTime:         UNKNOWN
Retention:              0
Location:               hdfs://172.17.0.2:9000/tables/external/examen_final
Table Type:             EXTERNAL_TABLE
Table Parameters:
        EXTERNAL                TRUE
        numFiles                8
        totalSize               55879352
        transient_lastDdlTime   1732489158

# Storage Information
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat:            org.apache.hadoop.mapred.TextInputFormat
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
Compressed:             No
Num Buckets:            -1
Bucket Columns:         []
Sort Columns:           []
Storage Desc Params:
        field.delim             ,
        serialization.format    ,
Time taken: 0.1 seconds, Fetched: 38 row(s)


----------------------------------------
----------------------------------------

### Vamos a repetir lo mismo realizado, para obtener la tabla segun Schema 2

##Cambiamos la separación de los datos de los archivos de ";" a "," Y habilitamos a que lea los emcabezados
>>> df = spark.read.option("header", "true").option("sep", ";").csv("/ingest/aeropuertos_detalle.csv")
>>> df = printSchema()

##Verificamos
root
 |-- local: string (nullable = true)
 |-- oaci: string (nullable = true)
 |-- iata: string (nullable = true)
 |-- tipo: string (nullable = true)
 |-- denominacion: string (nullable = true)
 |-- coordenadas: string (nullable = true)
 |-- latitud: string (nullable = true)
 |-- longitud: string (nullable = true)
 |-- elev: string (nullable = true)
 |-- uom_elev: string (nullable = true)
 |-- ref: string (nullable = true)
 |-- distancia_ref: string (nullable = true)
 |-- direccion_ref: string (nullable = true)
 |-- condicion: string (nullable = true)
 |-- control: string (nullable = true)
 |-- region: string (nullable = true)
 |-- fir: string (nullable = true)
 |-- uso: string (nullable = true)
 |-- trafico: string (nullable = true)
 |-- sna: string (nullable = true)
 |-- concesionado: string (nullable = true)
 |-- provincia: string (nullable = true)
 |-- inhab: string (nullable = true)



##Casteamos y verificamos los cambios con show y printSchema

>>> df_2 = df.select(df.local.alias("aeropuerto"), df.oaci.alias("oac"), df.iata, df.tipo, df.denominacion, df.coordenadas, df.latitud, df.longitud, df.elev.cast("float"), df.uom_elev, df.ref, df.distancia_ref.cast("float"), df.direccion_ref, df.condicion, df.control, df.region, df.uso, df.trafico, df.sna, df.concesionado, df.provincia)
>>> df_2.show(10)
+----------+----+----+---------+--------------------+--------------------+------------+------------+-----+--------+--------------------+-------------+-------------+---------+---------+------+-------+-------------+---+------------+--------------------+
|aeropuerto| oac|iata|     tipo|        denominacion|         coordenadas|     latitud|    longitud| elev|uom_elev|                 ref|distancia_ref|direccion_ref|condicion|  control|region|    uso|      trafico|sna|concesionado|           provincia|
+----------+----+----+---------+--------------------+--------------------+------------+------------+-----+--------+--------------------+-------------+-------------+---------+---------+------+-------+-------------+---+------------+--------------------+
|       ACB|null|null|Aeródromo|CORONEL BOGADO/AG...|"33°16'20""S  60°...|-60.57066000|-33.27226000| 44.0|  Metros|      Coronel Bogado|          6.0|           NE|  PRIVADO|NOCONTROL|  RACE|AEROAPP|     Nacional| NO|          NO|            SANTA FÉ|
|       ACH|null|null|Aeródromo|        GENERAL ACHA|"37°24' 6""S  64°...|-64.61351000|-37.40164000|277.0|  Metros|        General Acha|          3.0|           SO|  PUBLICO|NOCONTROL|  RACE|  CIVIL|     Nacional| NO|          NO|            LA PAMPA|
|       ACM|null|null|Aeródromo|ARRECIFES/LA CURA...|"34° 4'33""S  60°...|-60.14170000|-34.07574000| 37.0|  Metros|           Arrecifes|          4.0|          OSO|  PRIVADO|NOCONTROL|  RACE|  CIVIL|     Nacional| NO|          NO|        BUENOS AIRES|
|       ADO|SAWD| PUD|Aeródromo|      PUERTO DESEADO|"47°44' 6""S  65°...|-65.90410000|-47.73511000| 82.0|  Metros|      Puerto Deseado|          2.0|            N|  PUBLICO|  AERADIO|  RASU|  CIVIL|     Nacional| NO|          NO|          SANTA CRUZ|
|       ADT|null|null|Aeródromo|BANDERA/AGROSERVI...|"28°51'19""S  62°...|-62.26462000|-28.85541000| 75.0|  Metros|             Bandera|          4.0|            N|  PRIVADO|NOCONTROL|  RANO|AEROAPP|     Nacional| NO|          NO| SANTIAGO DEL ESTERO|
|       ADU|null|null|Aeródromo|       BANDERA/DUTTO|"28°52' 1""S  62°...|-62.23812000|-28.86691000| 87.0|  Metros|             Bandera|          3.0|           NE|  PRIVADO|NOCONTROL|  RANO|AEROAPP|     Nacional| NO|          NO| SANTIAGO DEL ESTERO|
|       AER|SABE| AEP|Aeródromo|BUENOS AIRES/AERO...|"34°33'32""S  58°...|-58.41638889|-34.55888889|  5.6|  Metros|Ciudad de Buenos ...|          2.0|           NE|  PUBLICO|  CONTROL|  RACE|  JOINT|Internacional| SI|          SI|CIUDAD AUTÓNOMA D...|
|       AGI|SAVA|null|Aeródromo|   PIEDRA DEL ÁGUILA|"40°11'32""S  70°...|-70.01075000|-40.19232000|649.0|  Metros|   Piedra del Águila|         17.0|          SSE|  PRIVADO|NOCONTROL|  RACE|   null|     Nacional| NO|          NO|             NEUQUÉN|
|       AGR|null|null|Aeródromo|         ALTA GRACIA|"31°39' 4""S  64°...|-64.39388889|-31.65111111|533.0|  Metros|         Alta Gracia|          2.0|            E|  PUBLICO|NOCONTROL|  RANO|  CIVIL|     Nacional| NO|          NO|             CÓRDOBA|
|       AII|null|null|Aeródromo| CHACABUCO/LAS DOS A|"34°48'40""S  60°...|-60.51661000|-34.81116000| 60.0|  Metros|           Chacabuco|         20.0|          SSO|  PRIVADO|NOCONTROL|  RACE|AEROAPP|     Nacional| NO|          NO|        BUENOS AIRES|
+----------+----+----+---------+--------------------+--------------------+------------+------------+-----+--------+--------------------+-------------+-------------+---------+---------+------+-------+-------------+---+------------+--------------------+
only showing top 10 rows

>>> df_2.printSchema()
root
 |-- aeropuerto: string (nullable = true)
 |-- oac: string (nullable = true)
 |-- iata: string (nullable = true)
 |-- tipo: string (nullable = true)
 |-- denominacion: string (nullable = true)
 |-- coordenadas: string (nullable = true)
 |-- latitud: string (nullable = true)
 |-- longitud: string (nullable = true)
 |-- elev: float (nullable = true)
 |-- uom_elev: string (nullable = true)
 |-- ref: string (nullable = true)
 |-- distancia_ref: float (nullable = true)
 |-- direccion_ref: string (nullable = true)
 |-- condicion: string (nullable = true)
 |-- control: string (nullable = true)
 |-- region: string (nullable = true)
 |-- uso: string (nullable = true)
 |-- trafico: string (nullable = true)
 |-- sna: string (nullable = true)
 |-- concesionado: string (nullable = true)
 |-- provincia: string (nullable = true)

##Creamos una vista de esa nueva tabla
>>> df_2.createOrReplaceTempView("df2_v")


df_cast_nombres = spark.sql("""SELECT CAST(fecha AS DATE) AS fecha, CAST(Hora_UTC AS STRING) AS hora_UTC, CAST("Clase de Vuelo (todos los vuelos)" AS STRING) AS clase_de_vuelo,CAST(Clasificación_Vuelo AS STRING) AS clasificacion_de_vuelo, CAST(Tipo_de_Movimiento AS STRING) AS tipo_de_movimiento, CAST(Aeropuerto AS STRING) AS aeropuerto, CAST("Origen / Destino" AS STRING) AS origen_destino, CAST(Aerolinea_Nombre AS STRING) AS aerolinea_nombre, CAST(Aeronave AS STRING) AS aeronave, CAST(pasajeros AS INT) AS pasajeros FROM df_2122_cast_v""")


