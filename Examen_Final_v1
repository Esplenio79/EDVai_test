##Ejercicio 1

##Ingestamos los archivos relacionados con transporte aéreo de Argentina con WGET desde:
2021:
https://dataengineerpublic.blob.core.windows.net/data-engineer/2021-informe-ministerio.csv
2022:
https://dataengineerpublic.blob.core.windows.net/data-engineer/202206-informe-ministerio.csv
Aeropuertos_detalles:
https://dataengineerpublic.blob.core.windows.net/data-engineer/aeropuertos_detalle.csv

##Los enviamos a hdfs y verificamos que se encuentran en la carpeta /ingest
plchiapero@LAPTOP-HJNIQGOK:~$ docker exec -it edvai_hadoop /bin/bash
root@7b946e8f971d:/# su hadoop
hadoop@7b946e8f971d:/$ hdfs dfs -ls /ingest/
Found 4 items
-rw-r--r--   1 hadoop supergroup   32322556 2024-09-29 17:21 /ingest/2021-informe-ministerio.csv
-rw-r--r--   1 hadoop supergroup   22833520 2024-09-29 18:09 /ingest/202206-informe-ministerio.csv
-rw-r--r--   1 hadoop supergroup     136007 2024-09-29 18:10 /ingest/aeropuertos_detalle.csv

hadoop@7b946e8f971d:/$ pyspark

##Cambiamos la separación de los datos de los archivos de ";" a ","
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.2.0
      /_/

Using Python version 3.8.10 (default, Mar 15 2022 12:22:08)
Spark context Web UI available at http://7b946e8f971d:4040
Spark context available as 'sc' (master = yarn, app id = application_1727916311286_0001).
SparkSession available as 'spark'.

>>> df2022 = spark.read.option("header", "true").option("sep", ";").csv("/ingest/202206-informe-ministerio.csv")
>>> df2021 = spark.read.option("header", "true").option("sep", ";").csv("/ingest/2021-informe-ministerio.csv")
>>> df2022.printSchema()
root
 |-- Fecha: string (nullable = true)
 |-- Hora UTC: string (nullable = true)
 |-- Clase de Vuelo (todos los vuelos): string (nullable = true)
 |-- Clasificación Vuelo: string (nullable = true)
 |-- Tipo de Movimiento: string (nullable = true)
 |-- Aeropuerto: string (nullable = true)
 |-- Origen / Destino: string (nullable = true)
 |-- Aerolinea Nombre: string (nullable = true)
 |-- Aeronave: string (nullable = true)
 |-- Pasajeros: string (nullable = true)
 |-- Calidad dato: string (nullable = true)

>>> df2021.printSchema()
root
 |-- Fecha: string (nullable = true)
 |-- Hora UTC: string (nullable = true)
 |-- Clase de Vuelo (todos los vuelos): string (nullable = true)
 |-- Clasificación Vuelo: string (nullable = true)
 |-- Tipo de Movimiento: string (nullable = true)
 |-- Aeropuerto: string (nullable = true)
 |-- Origen / Destino: string (nullable = true)
 |-- Aerolinea Nombre: string (nullable = true)
 |-- Aeronave: string (nullable = true)
 |-- Pasajeros: string (nullable = true)
 |-- Calidad dato: string (nullable = true)

##Unimos las dos tablas con UNION
>>> df_2122 = df2021.union(df2022)

##Creamos una vista de esa nueva tabla
>>> df_2122.createOrReplaceTempView("df_2122_v")

##Casteamos y verificamos los cambios con printSchema y show
>>> from pyspark.sql.functions import to_date, col
>>> df_2122_cast = df_2122.withColumn("fecha", to_date(col("fecha"), "dd/MM/yyyy")).withColumn("pasajeros", col("pasajeros").cast("int"))
>>> df_2122_cast.printSchema()
root
 |-- fecha: date (nullable = true)
 |-- Hora UTC: string (nullable = true)
 |-- Clase de Vuelo (todos los vuelos): string (nullable = true)
 |-- Clasificación Vuelo: string (nullable = true)
 |-- Tipo de Movimiento: string (nullable = true)
 |-- Aeropuerto: string (nullable = true)
 |-- Origen / Destino: string (nullable = true)
 |-- Aerolinea Nombre: string (nullable = true)
 |-- Aeronave: string (nullable = true)
 |-- pasajeros: integer (nullable = true)
 |-- Calidad dato: string (nullable = true)

>>> df_2122_cast.show(10)
+----------+--------+---------------------------------+-------------------+------------------+----------+----------------+--------------------+----------------+---------+------------+
|     fecha|Hora UTC|Clase de Vuelo (todos los vuelos)|Clasificación Vuelo|Tipo de Movimiento|Aeropuerto|Origen / Destino|    Aerolinea Nombre|        Aeronave|pasajeros|Calidad dato|
+----------+--------+---------------------------------+-------------------+------------------+----------+----------------+--------------------+----------------+---------+------------+
|2021-01-01|   00:02|             Vuelo Privado con...|          Domestico|          Despegue|       PAR|             ROS|                   0|    PA-PA-28-181|        0|  DEFINITIVO|
|2021-01-01|   00:24|                          Regular|          Domestico|        Aterrizaje|       EZE|             GRA|AEROLINEAS ARGENT...|     BO-B737-8MB|       70|  DEFINITIVO|
|2021-01-01|   00:26|                          Regular|          Domestico|        Aterrizaje|       EZE|             ECA|AEROLINEAS ARGENT...|      BO-737-800|       70|  DEFINITIVO|
|2021-01-01|   00:29|                          Regular|          Domestico|        Aterrizaje|       EZE|             SAL|AEROLINEAS ARGENT...|    BO-B-737-76N|       12|  DEFINITIVO|

##Generamos una vista de este nuevo df
>>> df_2122_cast.createOrReplaceTempView("df_2122_cast_v")

##Casteamos de acuerdo a lo solicitado en el punto del Schema 1
>>> df_cast_nombres = spark.sql("SELECT to_date(fecha, 'dd/MM/yyyy') AS fecha, CAST(`Hora UTC` AS STRING) AS hora_utc, CAST(`Clase de Vuelo (todos los vuelos)` AS STRING) AS clase_de_vuelo, CAST(`Clasificación Vuelo` AS STRING) AS clasificacion_de_vuelo, CAST(`Tipo de Movimiento` AS STRING) AS tipo_de_movimiento, CAST(aeropuerto AS STRING) AS aeropuerto, CAST(`Origen / Destino` AS STRING) AS origen_destino, CAST(`Aerolinea Nombre` AS STRING) AS aerolinea_nombre, CAST(aeronave AS STRING) AS aeronave, COALESCE(CAST(pasajeros AS INTEGER), 0) AS pasajeros FROM df_2122_cast_v")
>>> df_cast_nombres.printSchema()
root
 |-- fecha: date (nullable = true)
 |-- hora_utc: string (nullable = true)
 |-- clase_de_vuelo: string (nullable = true)
 |-- clasificacion_de_vuelo: string (nullable = true)
 |-- tipo_de_movimiento: string (nullable = true)
 |-- aeropuerto: string (nullable = true)
 |-- origen_destino: string (nullable = true)
 |-- aerolinea_nombre: string (nullable = true)
 |-- aeronave: string (nullable = true)
 |-- pasajeros: integer (nullable = false)

>>> df_cast_nombres.show(2)
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+------------+---------+
|     fecha|hora_utc|      clase_de_vuelo|clasificacion_de_vuelo|tipo_de_movimiento|aeropuerto|origen_destino|    aerolinea_nombre|    aeronave|pasajeros|
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+------------+---------+
|2021-01-01|   00:02|Vuelo Privado con...|             Domestico|          Despegue|       PAR|           ROS|                   0|PA-PA-28-181|        0|
|2021-01-01|   00:24|             Regular|             Domestico|        Aterrizaje|       EZE|           GRA|AEROLINEAS ARGENT...| BO-B737-8MB|       70|
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+------------+---------+
only showing top 2 rows

##Generamos una vista para usar en SQL

>>> df_cast_nombres.createOrReplaceTempView("df_2122_cast_v_final")

##Chequeamos la vista generada usando SQL 

>>> spark.sql("DESCRIBE df_2122_cast_v_final").show()
+--------------------+---------+-------+
|            col_name|data_type|comment|
+--------------------+---------+-------+
|               fecha|     date|   null|
|            hora_utc|   string|   null|
|      clase_de_vuelo|   string|   null|
|clasificacion_de_...|   string|   null|
|  tipo_de_movimiento|   string|   null|
|          aeropuerto|   string|   null|
|      origen_destino|   string|   null|
|    aerolinea_nombre|   string|   null|
|            aeronave|   string|   null|
|           pasajeros|      int|   null|
+--------------------+---------+-------+

##Generamos la vista filtrada segun solicitud punto 3
>>>> df_2122_filter = spark.sql("select * from df_2122_cast_v_final where fecha >= '2021-01-01' and fecha <= '2022-06-30'")

##Verificamos 
>>> df_2122_filter.show()

+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+----------------+---------+
|     fecha|hora_utc|      clase_de_vuelo|clasificacion_de_vuelo|tipo_de_movimiento|aeropuerto|origen_destino|    aerolinea_nombre|        aeronave|pasajeros|
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+----------------+---------+
|2021-01-01|   00:02|Vuelo Privado con...|             Domestico|          Despegue|       PAR|           ROS|                   0|    PA-PA-28-181|        0|
|2021-01-01|   00:24|             Regular|             Domestico|        Aterrizaje|       EZE|           GRA|AEROLINEAS ARGENT...|     BO-B737-8MB|       70|
|2021-01-01|   00:26|             Regular|             Domestico|        Aterrizaje|       EZE|           ECA|AEROLINEAS ARGENT...|      BO-737-800|       70|
|2021-01-01|   00:29|             Regular|             Domestico|        Aterrizaje|       EZE|           SAL|AEROLINEAS ARGENT...|    BO-B-737-76N|       12|
|2021-01-01|   00:37|             Regular|             Domestico|        Aterrizaje|       EZE|           TUC|AEROLINEAS ARGENT...|EMB-ERJ190100IGW|       26|
|2021-01-01|   00:59|             Regular|         Internacional|        Aterrizaje|       EZE|          SBGR|TURK HAVA YOLLARI...|               0|       62|
|2021-01-01|   01:00|Vuelo Privado con...|             Domestico|        Aterrizaje|       ROS|           PAR|                   0|    PA-PA-28-181|        0|
|2021-01-01|   01:12|             Regular|         Internacional|          Despegue|       EZE|          MMMX|AEROVIAS DE MEXIC...|               0|      198|
|2021-01-01|   01:52|             Regular|         Internacional|          Despegue|       EZE|          KDFW|AMERICAN AIRLINES...|               0|      193|
|2021-01-01|   02:08|             Regular|         Internacional|          Despegue|       EZE|          KMIA|AMERICAN AIRLINES...|               0|      255|
|2021-01-01|   02:39|             Regular|         Internacional|          Despegue|       EZE|          SBGR|TURK HAVA YOLLARI...|               0|      103|
|2021-01-01|   02:46|             Regular|         Internacional|          Despegue|       EZE|          KIAH|UNITED AIRLINES I...|               0|      229|
|2021-01-01|   03:30|             Regular|         Internacional|        Aterrizaje|       EZE|          MPTO|COMPAÑIA PANAMEÑA...|               0|       21|
|2021-01-01|   05:01|             Regular|         Internacional|          Despegue|       EZE|          MPTO|COMPAÑIA PANAMEÑA...|               0|      132|
|2021-01-01|   06:40|             Regular|         Internacional|        Aterrizaje|       EZE|          SBGR|       QATAR AIRWAYS|               0|        0|
|2021-01-01|   07:09|             Regular|             Domestico|          Despegue|       EZE|           ECA|AEROLINEAS ARGENT...|     BO-B737-800|       35|
|2021-01-01|   08:10|             Regular|             Domestico|          Despegue|       EZE|           JUJ|AEROLINEAS ARGENT...|EMB-ERJ190100IGW|       46|
|2021-01-01|   08:14|             Regular|             Domestico|          Despegue|       EZE|           BAR|AEROLINEAS ARGENT...|      BO-737-800|       81|
|2021-01-01|   08:30|             Regular|         Internacional|          Despegue|       EZE|          SEQM|       QATAR AIRWAYS|               0|        0|
|2021-01-01|   08:35|             Regular|             Domestico|          Despegue|       EZE|           USU|AEROLINEAS ARGENT...|     BO-B737-8MB|       74|
+----------+--------+--------------------+----------------------+------------------+----------+--------------+--------------------+----------------+---------+
only showing top 20 rows

##Creamos la vista fitrada para usar en Hive
>>> df_2122_filter.createOrReplaceTempView("df_2122_cast_final")

##Chequeamos la vista realizada
>>> spark.sql("DESCRIBE df_2122_cast_final").show()
+--------------------+---------+-------+
|            col_name|data_type|comment|
+--------------------+---------+-------+
|               fecha|     date|   null|
|            hora_utc|   string|   null|
|      clase_de_vuelo|   string|   null|
|clasificacion_de_...|   string|   null|
|  tipo_de_movimiento|   string|   null|
|          aeropuerto|   string|   null|
|      origen_destino|   string|   null|
|    aerolinea_nombre|   string|   null|
|            aeronave|   string|   null|
|           pasajeros|      int|   null|
+--------------------+---------+-------+


## En HIVE, damos de alta la BD que llamamos examen_final, luego chequeamos el alta correcta, y finalmente elegimos usar la BD que dimos de alta

hive> create database examen_final;
hive> show databases;
OK
examen_final
Time taken: 0.027 seconds, Fetched: 1 row(s)
hive> use examen_final;
OK

##Damos de alta las dos tablas 
DROP TABLE IF EXISTS examen_final.aeropuerto_detalle_tabla;

CREATE EXTERNAL TABLE IF NOT EXISTS examen_final.aeropuerto_detalles_tabla (
    aeropuerto STRING, oac STRING, iata STRING, tipo STRING, denominacion STRING,
    coordenadas STRING, latitud STRING, longitud STRING, elev FLOAT, uom_elev STRING,
    ref STRING, distancia_ref FLOAT, direccion_ref STRING, condicion STRING,
    control STRING, region STRING, uso STRING, trafico STRING, sna STRING,
    concesionado STRING, provincia STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LOCATION '/tables/external/examen_final/aeropuerto_detalle_tabla';


DROP TABLE IF EXISTS examen_final.aeropuerto_tabla;
CREATE EXTERNAL TABLE IF NOT EXISTS examen_final.aeropuerto_tabla (
    fecha DATE,
    hora_utc STRING,
    clase_de_vuelo STRING,
    clasificacion_de_vuelo STRING,
    tipo_de_movimiento STRING,
    aeropuerto STRING,
    origen_destino STRING,
    aerolinea_nombre STRING,
    aeronave STRING,
    pasajeros INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LOCATION '/tables/external/examen_final/aeropuerto_tabla';

OK
Time taken: 0.863 seconds
hive>

##Vuelvo a spark, y envío la vista del df a hive

>>> spark.sql("insert into examen_final.aeropuerto_tabla select * from df_2122_cast_v_final")
2024-11-24 19:59:11,787 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
DataFrame[]
>>>

#Chequeo que en hive esté la tabla
      hive> select * from aeropuerto_tabla limit 5;
OK
2021-01-01      00:02   Vuelo Privado con Matrícula Nacional    Domestico       Despegue        PAR     ROS     0      PA-PA-28-181                                                                               0
2021-01-01      00:24   Regular Domestico       Aterrizaje      EZE     GRA     AEROLINEAS ARGENTINAS SA        BO-B737-8MB                                                                                       70
2021-01-01      00:26   Regular Domestico       Aterrizaje      EZE     ECA     AEROLINEAS ARGENTINAS SA        BO-737-800                                                                                        70
2021-01-01      00:29   Regular Domestico       Aterrizaje      EZE     SAL     AEROLINEAS ARGENTINAS SA        BO-B-737-76N                                                                                      12
2021-01-01      00:37   Regular Domestico       Aterrizaje      EZE     TUC     AEROLINEAS ARGENTINAS SA        EMB-ERJ190100IGW                                                                                  26
Time taken: 0.398 seconds, Fetched: 5 row(s)
hive> describe aeropuerto_tabla;
OK
fecha                   date
hora_utc                string
clase_de_vuelo          string
clasificacion_de_vuelo  string
tipo_de_movimiento      string
aeropuerto              string
origen_destino          string
aerolinea_nombre        string
aeronave                string
pasajeros               int
Time taken: 0.071 seconds, Fetched: 10 row(s)
hive> describe formatted aeropuerto_tabla;
OK
# col_name              data_type               comment

fecha                   date
hora_utc                string
clase_de_vuelo          string
clasificacion_de_vuelo  string
tipo_de_movimiento      string
aeropuerto              string
origen_destino          string
aerolinea_nombre        string
aeronave                string
pasajeros               int

# Detailed Table Information
Database:               examen_final
Owner:                  hadoop
CreateTime:             Sun Nov 24 19:56:01 ART 2024
LastAccessTime:         UNKNOWN
Retention:              0
Location:               hdfs://172.17.0.2:9000/tables/external/examen_final
Table Type:             EXTERNAL_TABLE
Table Parameters:
        EXTERNAL                TRUE
        numFiles                8
        totalSize               55879352
        transient_lastDdlTime   1732489158

# Storage Information
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat:            org.apache.hadoop.mapred.TextInputFormat
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
Compressed:             No
Num Buckets:            -1
Bucket Columns:         []
Sort Columns:           []
Storage Desc Params:
        field.delim             ,
        serialization.format    ,
Time taken: 0.1 seconds, Fetched: 38 row(s)


----------------------------------------
----------------------------------------

### Vamos a repetir lo mismo realizado, para obtener la tabla segun Schema 2

##Cambiamos la separación de los datos de los archivos de ";" a "," Y habilitamos a que lea los emcabezados
>>> df = spark.read.option("header", "true").option("sep", ";").csv("/ingest/aeropuertos_detalle.csv")
>>> df.printSchema()

##Verificamos
root
 |-- local: string (nullable = true)
 |-- oaci: string (nullable = true)
 |-- iata: string (nullable = true)
 |-- tipo: string (nullable = true)
 |-- denominacion: string (nullable = true)
 |-- coordenadas: string (nullable = true)
 |-- latitud: string (nullable = true)
 |-- longitud: string (nullable = true)
 |-- elev: string (nullable = true)
 |-- uom_elev: string (nullable = true)
 |-- ref: string (nullable = true)
 |-- distancia_ref: string (nullable = true)
 |-- direccion_ref: string (nullable = true)
 |-- condicion: string (nullable = true)
 |-- control: string (nullable = true)
 |-- region: string (nullable = true)
 |-- fir: string (nullable = true)
 |-- uso: string (nullable = true)
 |-- trafico: string (nullable = true)
 |-- sna: string (nullable = true)
 |-- concesionado: string (nullable = true)
 |-- provincia: string (nullable = true)
 |-- inhab: string (nullable = true)



##Casteamos y verificamos los cambios con show y printSchema

>>> df_2 = df.select(df.local.alias("aeropuerto"), df.oaci.alias("oac"), df.iata, df.tipo, df.denominacion, df.coordenadas, df.latitud, df.longitud, df.elev.cast("float"), df.uom_elev, df.ref, df.distancia_ref.cast("float"), df.direccion_ref, df.condicion, df.control, df.region, df.uso, df.trafico, df.sna, df.concesionado, df.provincia)
>>> df_2.show(10)
+----------+----+----+---------+--------------------+--------------------+------------+------------+-----+--------+--------------------+-------------+-------------+---------+---------+------+-------+-------------+---+------------+--------------------+
|aeropuerto| oac|iata|     tipo|        denominacion|         coordenadas|     latitud|    longitud| elev|uom_elev|                 ref|distancia_ref|direccion_ref|condicion|  control|region|    uso|      trafico|sna|concesionado|           provincia|
+----------+----+----+---------+--------------------+--------------------+------------+------------+-----+--------+--------------------+-------------+-------------+---------+---------+------+-------+-------------+---+------------+--------------------+
|       ACB|null|null|Aeródromo|CORONEL BOGADO/AG...|"33°16'20""S  60°...|-60.57066000|-33.27226000| 44.0|  Metros|      Coronel Bogado|          6.0|           NE|  PRIVADO|NOCONTROL|  RACE|AEROAPP|     Nacional| NO|          NO|            SANTA FÉ|
|       ACH|null|null|Aeródromo|        GENERAL ACHA|"37°24' 6""S  64°...|-64.61351000|-37.40164000|277.0|  Metros|        General Acha|          3.0|           SO|  PUBLICO|NOCONTROL|  RACE|  CIVIL|     Nacional| NO|          NO|            LA PAMPA|
|       ACM|null|null|Aeródromo|ARRECIFES/LA CURA...|"34° 4'33""S  60°...|-60.14170000|-34.07574000| 37.0|  Metros|           Arrecifes|          4.0|          OSO|  PRIVADO|NOCONTROL|  RACE|  CIVIL|     Nacional| NO|          NO|        BUENOS AIRES|
|       ADO|SAWD| PUD|Aeródromo|      PUERTO DESEADO|"47°44' 6""S  65°...|-65.90410000|-47.73511000| 82.0|  Metros|      Puerto Deseado|          2.0|            N|  PUBLICO|  AERADIO|  RASU|  CIVIL|     Nacional| NO|          NO|          SANTA CRUZ|
|       ADT|null|null|Aeródromo|BANDERA/AGROSERVI...|"28°51'19""S  62°...|-62.26462000|-28.85541000| 75.0|  Metros|             Bandera|          4.0|            N|  PRIVADO|NOCONTROL|  RANO|AEROAPP|     Nacional| NO|          NO| SANTIAGO DEL ESTERO|
|       ADU|null|null|Aeródromo|       BANDERA/DUTTO|"28°52' 1""S  62°...|-62.23812000|-28.86691000| 87.0|  Metros|             Bandera|          3.0|           NE|  PRIVADO|NOCONTROL|  RANO|AEROAPP|     Nacional| NO|          NO| SANTIAGO DEL ESTERO|
|       AER|SABE| AEP|Aeródromo|BUENOS AIRES/AERO...|"34°33'32""S  58°...|-58.41638889|-34.55888889|  5.6|  Metros|Ciudad de Buenos ...|          2.0|           NE|  PUBLICO|  CONTROL|  RACE|  JOINT|Internacional| SI|          SI|CIUDAD AUTÓNOMA D...|
|       AGI|SAVA|null|Aeródromo|   PIEDRA DEL ÁGUILA|"40°11'32""S  70°...|-70.01075000|-40.19232000|649.0|  Metros|   Piedra del Águila|         17.0|          SSE|  PRIVADO|NOCONTROL|  RACE|   null|     Nacional| NO|          NO|             NEUQUÉN|
|       AGR|null|null|Aeródromo|         ALTA GRACIA|"31°39' 4""S  64°...|-64.39388889|-31.65111111|533.0|  Metros|         Alta Gracia|          2.0|            E|  PUBLICO|NOCONTROL|  RANO|  CIVIL|     Nacional| NO|          NO|             CÓRDOBA|
|       AII|null|null|Aeródromo| CHACABUCO/LAS DOS A|"34°48'40""S  60°...|-60.51661000|-34.81116000| 60.0|  Metros|           Chacabuco|         20.0|          SSO|  PRIVADO|NOCONTROL|  RACE|AEROAPP|     Nacional| NO|          NO|        BUENOS AIRES|
+----------+----+----+---------+--------------------+--------------------+------------+------------+-----+--------+--------------------+-------------+-------------+---------+---------+------+-------+-------------+---+------------+--------------------+
only showing top 10 rows

>>> df_2.printSchema()
root
 |-- aeropuerto: string (nullable = true)
 |-- oac: string (nullable = true)
 |-- iata: string (nullable = true)
 |-- tipo: string (nullable = true)
 |-- denominacion: string (nullable = true)
 |-- coordenadas: string (nullable = true)
 |-- latitud: string (nullable = true)
 |-- longitud: string (nullable = true)
 |-- elev: float (nullable = true)
 |-- uom_elev: string (nullable = true)
 |-- ref: string (nullable = true)
 |-- distancia_ref: float (nullable = true)
 |-- direccion_ref: string (nullable = true)
 |-- condicion: string (nullable = true)
 |-- control: string (nullable = true)
 |-- region: string (nullable = true)
 |-- uso: string (nullable = true)
 |-- trafico: string (nullable = true)
 |-- sna: string (nullable = true)
 |-- concesionado: string (nullable = true)
 |-- provincia: string (nullable = true)

##Creamos una vista de esa nueva tabla
>>> df_2.createOrReplaceTempView("df2_v")


##Chequeamos la vista generada usando SQL 
>>> spark.sql("DESCRIBE df2_v").show()

+-------------+---------+-------+
|     col_name|data_type|comment|
+-------------+---------+-------+
|   aeropuerto|   string|   null|
|          oac|   string|   null|
|         iata|   string|   null|
|         tipo|   string|   null|
| denominacion|   string|   null|
|  coordenadas|   string|   null|
|      latitud|   string|   null|
|     longitud|   string|   null|
|         elev|    float|   null|
|     uom_elev|   string|   null|
|          ref|   string|   null|
|distancia_ref|    float|   null|
|direccion_ref|   string|   null|
|    condicion|   string|   null|
|      control|   string|   null|
|       region|   string|   null|
|          uso|   string|   null|
|      trafico|   string|   null|
|          sna|   string|   null|
| concesionado|   string|   null|
+-------------+---------+-------+
only showing top 20 rows

###Envío la vista del df a hive
>>>> spark.sql("insert into examen_final.aeropuerto_detalles_tabla select * from df2_v")

##Chequeo que en hive esté la tabla
hive> select * from aeropuerto_detalles_tabla limit 5;
OK
ACB     NULL    NULL    Aeródromo       CORONEL BOGADO/AGROSERVICIOS    "33°16'20""S  60°34'14""W"      -60.57066000   -33.27226000                                                                               44.0     Metros  Coronel Bogado  6.0     NE      PRIVADO NOCONTROL       RACE    AEROAPP Nacional        NO      NO     SANTA FÉ
ACH     NULL    NULL    Aeródromo       GENERAL ACHA    "37°24' 6""S  64°36'49""W"      -64.61351000    -37.40164000   277.0                                                                                      Metros   General Acha    3.0     SO      PUBLICO NOCONTROL       RACE    CIVIL   Nacional        NO      NO      LA PAMPA
ACM     NULL    NULL    Aeródromo       ARRECIFES/LA CURA MALAL "34° 4'33""S  60° 8'30""W"      -60.14170000    -34.07574000                                                                                      37.0     Metros  Arrecifes       4.0     OSO     PRIVADO NOCONTROL       RACE    CIVIL   Nacional        NO      NO     BUENOS AIRES
ADO     SAWD    PUD     Aeródromo       PUERTO DESEADO  "47°44' 6""S  65°54'15""W"      -65.90410000    -47.73511000   82.0                                                                                       Metros   Puerto Deseado  2.0     N       PUBLICO AERADIO RASU    CIVIL   Nacional        NO      NO      SANTA CRUZ
ADT     NULL    NULL    Aeródromo       BANDERA/AGROSERVICIOS DOÑA TERESA       "28°51'19""S  62°15'53""W"      -62.26462000                                                                                      -28.85541000     75.0    Metros  Bandera 4.0     N       PRIVADO NOCONTROL       RANO    AEROAPP Nacional        NO     NO                                                                                         SANTIAGO DEL ESTERO
Time taken: 0.207 seconds, Fetched: 5 row(s)

hive> describe formatted aeropuerto_detalles_tabla;
OK
# col_name              data_type               comment

aeropuerto              string
oac                     string
iata                    string
tipo                    string
denominacion            string
coordenadas             string
latitud                 string
longitud                string
elev                    float
uom_elev                string
ref                     string
distancia_ref           float
direccion_ref           string
condicion               string
control                 string
region                  string
uso                     string
trafico                 string
sna                     string
concesionado            string
provincia               string

# Detailed Table Information
Database:               examen_final
Owner:                  hadoop
CreateTime:             Wed Jan 08 15:13:01 ART 2025
LastAccessTime:         UNKNOWN
Retention:              0
Location:               hdfs://172.17.0.2:9000/tables/external/examen_final/aeropuerto_detalle_tabla
Table Type:             EXTERNAL_TABLE
Table Parameters:
        EXTERNAL                TRUE
        numFiles                1
        totalSize               129695
        transient_lastDdlTime   1736979731

# Storage Information
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat:            org.apache.hadoop.mapred.TextInputFormat
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
Compressed:             No
Num Buckets:            -1
Bucket Columns:         []
Sort Columns:           []
Storage Desc Params:
        field.delim             ,
        serialization.format    ,
Time taken: 0.071 seconds, Fetched: 49 row(s)



df_cast_nombres = spark.sql("""SELECT CAST(fecha AS DATE) AS fecha, CAST(Hora_UTC AS STRING) AS hora_UTC, CAST("Clase de Vuelo (todos los vuelos)" AS STRING) AS clase_de_vuelo,CAST(Clasificación_Vuelo AS STRING) AS clasificacion_de_vuelo, CAST(Tipo_de_Movimiento AS STRING) AS tipo_de_movimiento, CAST(Aeropuerto AS STRING) AS aeropuerto, CAST("Origen / Destino" AS STRING) AS origen_destino, CAST(Aerolinea_Nombre AS STRING) AS aerolinea_nombre, CAST(Aeronave AS STRING) AS aeronave, CAST(pasajeros AS INT) AS pasajeros FROM df_2122_cast_v""")

******************

Ej 1 TAREA 3:

Incorporamos al dag a los archivos ingest.sh y transformation.py al DAG que va a correr en Airflow. Los dos van a responder al script ingest-transform.py

******************

##Las respuestas del ejercicio 1 de las tareas 6 a 13 se encuentran en el siguiente enlance de COLAB:
https://colab.research.google.com/drive/1a7KZbCc7NgrHP1ymWWB-7Wc3vj_2eu8h?usp=sharing

******************
******************
******************

##Ejercicio Google Skills Boost - Examen Final
Los puntos que fueron solicitados en el examen se encuentran desarrollados en el siguiente link

https://docs.google.com/document/d/1eZNAvCEMup4p8P79WW3cFfXQcRdNINvw4Fpjwhw7thw/edit?usp=sharing

><************************************><            ><************************************><
><************************************><            ><************************************><
><************************************><            ><************************************><

##Ejercicio 2

1) Creamos en Hive una base de datos llamada car_rental_db y una tabla llamada car_rental_analytics con los campos dados:

hive> 
CREATE DATABASE IF NOT EXISTS car_rental_db;
USE car_rental_db;

CREATE EXTERNAL TABLE IF NOT EXISTS car_rental_db.car_rental_analytics (
    >     fuel_type STRING,
    >     rating INT,
    >     renter_trips_taken INT,
    >     review_count INT,
    >     city STRING,
    >     state_name STRING,
    >     owner_id INT,
    >     rate_daily INT,
    >     make STRING,
    >     model STRING,
    >     year INT
    > )
    > ROW FORMAT DELIMITED
    > FIELDS TERMINATED BY ','
    > LOCATION '/tables/external/car_rental_db/car_rental_analytics';

hive>  describe car_rental_analytics;
OK
fuel_type               string
rating                  int
renter_trips_taken      int
review_count            int
city                    string
state_name              string
owner_id                int
rate_daily              int
make                    string
model                   string
year                    int
Time taken: 0.058 seconds, Fetched: 11 row(s)

2)Se crean scripts para ingestar dos files:

